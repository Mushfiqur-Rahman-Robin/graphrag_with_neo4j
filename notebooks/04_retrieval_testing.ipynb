{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "433e7e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mushfiq/Desktop/graphrag_with_neo4j/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.retrieval_system import RetrievalSystem\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e20a6186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 2 processed documents\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open('../processed_documents.pkl', 'rb') as f:\n",
    "        documents = pickle.load(f)\n",
    "    print(f\"‚úÖ Loaded {len(documents)} processed documents\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå No processed documents found. Run 02_document_processing.ipynb first\")\n",
    "    documents = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bddfe23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Initializing retrieval system...\n",
      "Creating vector store...\n",
      "Vector store created with 2 documents\n",
      "‚ö†Ô∏è langchain-graph-retriever not available; falling back to vector-only retriever.\n",
      "‚úÖ Retrieval system ready!\n"
     ]
    }
   ],
   "source": [
    "if documents:\n",
    "    print(\"üîÑ Initializing retrieval system...\")\n",
    "    retrieval_system = RetrievalSystem(documents)\n",
    "    print(\"‚úÖ Retrieval system ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "213e3da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Testing basic queries...\n",
      "\n",
      "üìù Query 1: What is GraphRAG?\n",
      "‚úÖ Response: GraphRAG is a system that combines graph traversal with vector search to enhance context understanding and retrieval accuracy. It is implemented using technologies like LangChain, Gemini (a large language model), and Neo4j (a graph database) with Python.\n",
      "\n",
      "Key components of a GraphRAG system include:\n",
      "*   **Document Processing**: Utilizes semantic chunking to process documents.\n",
      "*   **Knowledge Graph...\n",
      "\n",
      "üìù Query 2: What technologies are used in this system?\n",
      "‚úÖ Response: The technologies used in this system are:\n",
      "\n",
      "*   **LangChain**: A framework for building LLM applications. (Source: sample_graphrag.docx)\n",
      "*   **Gemini**: Google's large language model for text processing. (Source: sample_graphrag.docx)\n",
      "*   **Neo4j**: A graph database for storing relationships. (Source: sample_graphrag.docx)\n",
      "*   **Python**: The programming language used for implementation. (Source: s...\n",
      "\n",
      "üìù Query 3: What are the benefits of using GraphRAG?\n",
      "‚úÖ Response: Based on the provided context, the benefits of using GraphRAG are:\n",
      "\n",
      "*   **Better context understanding through relationships** (Source: sample_graphrag.docx)\n",
      "*   **More accurate retrieval through graph traversal** (Source: sample_graphrag.docx)\n",
      "*   **Explainable results through graph structure** (Source: sample_graphrag.docx)...\n",
      "\n",
      "üìù Query 4: How does the system work?\n",
      "‚úÖ Response: The system works by processing documents, creating a knowledge graph, storing vector embeddings, and then using a hybrid retrieval method.\n",
      "\n",
      "Here's a breakdown of how it works, based on the provided context:\n",
      "\n",
      "1.  **Document Processing**: The system first processes documents using **semantic chunking**. This means it breaks down the documents into meaningful segments.\n",
      "2.  **Knowledge Graph Creation*...\n",
      "\n",
      "üìù Query 5: What are the key components?\n",
      "‚úÖ Response: The key components of the GraphRAG system implementation are:\n",
      "\n",
      "1.  **Document Processing**: Uses semantic chunking to process documents.\n",
      "2.  **Knowledge Graph Creation**: Extracts entities and relationships using an LLM.\n",
      "3.  **Vector Storage**: Stores embeddings for similarity search.\n",
      "4.  **Hybrid Retrieval**: Combines graph traversal with vector search.\n",
      "\n",
      "(Source: sample_graphrag.docx)...\n"
     ]
    }
   ],
   "source": [
    "if documents:\n",
    "    test_queries = [\n",
    "        \"What is GraphRAG?\",\n",
    "        \"What technologies are used in this system?\",\n",
    "        \"What are the benefits of using GraphRAG?\",\n",
    "        \"How does the system work?\",\n",
    "        \"What are the key components?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"üß™ Testing basic queries...\")\n",
    "    for i, query in enumerate(test_queries, 1):\n",
    "        print(f\"\\nüìù Query {i}: {query}\")\n",
    "        try:\n",
    "            response = retrieval_system.query(query)\n",
    "            print(f\"‚úÖ Response: {response[:400]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb5e3a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üí¨ Interactive Query Interface\n",
      "Type 'quit' to exit\n",
      "üîÑ Processing...\n",
      "\n",
      "ü§ñ Response:\n",
      "The GraphRAG system is used to enhance information retrieval and understanding by combining the strengths of large language models (LLMs) with graph databases.\n",
      "\n",
      "Specifically, its uses include:\n",
      "*   **Better Context Understanding:** It leverages relationships within a knowledge graph to provide a richer understanding of the context surrounding information (Source: sample_graphrag.docx).\n",
      "*   **More Accurate Retrieval:** By combining graph traversal with vector search (hybrid retrieval), it enables more precise and relevant information retrieval (Source: sample_graphrag.docx).\n",
      "*   **Explainable Results:** The inherent structure of the graph allows for more transparent and explainable results, as the connections and relationships can be visualized and understood (Source: sample_graphrag.docx).\n",
      "\n",
      "In essence, it processes documents using semantic chunking, creates a knowledge graph by extracting entities and relationships with an LLM, stores embeddings for similarity search, and then uses a hybrid approach for retrieval.\n",
      "\n",
      "üëã Goodbye!\n"
     ]
    }
   ],
   "source": [
    "if documents:\n",
    "    print(\"\\nüí¨ Interactive Query Interface\")\n",
    "    print(\"Type 'quit' to exit\")\n",
    "    \n",
    "    while True:\n",
    "        user_query = input(\"\\nü§î Your question: \").strip()\n",
    "        \n",
    "        if user_query.lower() in ['quit', 'exit', 'q']:\n",
    "            print(\"üëã Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        if user_query:\n",
    "            try:\n",
    "                print(\"üîÑ Processing...\")\n",
    "                response = retrieval_system.query(user_query)\n",
    "                print(f\"\\nü§ñ Response:\\n{response}\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error: {str(e)}\")\n",
    "        else:\n",
    "            print(\"Please enter a question.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1b7fbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Performance Testing...\n",
      "\n",
      "Query: What is the main purpose of this system?\n",
      "Response time: 2.83 seconds\n",
      "Response length: 369 characters\n",
      "\n",
      "Query: List all the technologies mentioned\n",
      "Response time: 1.54 seconds\n",
      "Response length: 202 characters\n",
      "\n",
      "Query: How do the components work together?\n",
      "Response time: 4.79 seconds\n",
      "Response length: 2364 characters\n"
     ]
    }
   ],
   "source": [
    "if documents:\n",
    "    import time\n",
    "    \n",
    "    print(\"üìä Performance Testing...\")\n",
    "    \n",
    "    performance_queries = [\n",
    "        \"What is the main purpose of this system?\",\n",
    "        \"List all the technologies mentioned\",\n",
    "        \"How do the components work together?\",\n",
    "    ]\n",
    "    \n",
    "    for query in performance_queries:\n",
    "        start_time = time.time()\n",
    "        response = retrieval_system.query(query)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"\\nQuery: {query}\")\n",
    "        print(f\"Response time: {end_time - start_time:.2f} seconds\")\n",
    "        print(f\"Response length: {len(response)} characters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphrag_with_neo4j",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
